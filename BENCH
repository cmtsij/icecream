
There were no structured benchmarks of icecream, so I started some. I'm benchmarking 5 runs
each, throwing away the worst and the best run, and then averaging the rest of the 3.
There are two machines in the cluster, both single cpu and both about the same speed (1.7GHz
Pentium M). Normally the tests are done via otherwise idle WLAN (54MBit). WLAN has a bad
latency and very bad throughput, which gives icecream a hard time, and should be compareable
to a loaded cabled network environment. For comparison, I repeated some tests via 100MBit
cabled LAN.

I'm testing linux 2.6.16 (defconfig), which is a set of small C files with sometimes larger
C files inbetween. its a tough benchmark because compiling C is rather quick, so remote
overhead has to be low.

No icecream:

make  -j1:     315s
make  -j2:     322s
make  -j3:     324s
make -j10:     334s

result: without icecream, starting more compilers than CPUs available is a bad idea.


icecream wrapper, no scheduler.

make  -j1:     323s
make -j10:     340s

result: Overhead of just using icecream without cluster is neglectible (2%) in all cases.

dirk's no-latency icecream: remote daemon with -m 1:

make  -j1:     418s
make  -j2:     397s
make  -j3:     263s
make -j10:     230s
make -j10/100: 203s
make -j100:    231s
make -j10/100: 202s

result: Enabling icecream without parallel compilation is a horrible mistake. icecream
must be tuned to detect and compensate this situation better. Maximum performance
improvement of icecream is 27% (LAN: 36%) out of the theoretical 50%.

======================================================================

Qt 3.3.6's src/ subdirectory. This is a bunch of medium and large C++ files. It
gives icecream good opportunities because compilation time is comparatively low
and the preprocessed files are not too large (low STL usage).


No icecream:

make  -j1:     368s
make  -j3:     363s

result: apparently there is a small win by starting more compilers than CPUs in parallel.
Perhaps the I/O overhead is not neglectible like in the linux kernel case.

dirk's no-latency icecream, remote daemon with -m 2:

make  -j1:     572s
make  -j3:     273s
make -j10:     269s
make -j10/100: 239s
make -j100:    282s

result: again, not compiling in parallel is a deadly sin. trying to overload the cluster
with very high parallelism as well. Maximum performance improvement is again 27% and
36% for LAN. That these numbers compare equally with the Linux kernel case is astonishing
and needs explanation.

Now, to make sure that the no-latency patch hasn't regressed anything, we're comparing with
stock 0.7 (which already has some performance improvements over 0.6):


make  -j1:      569s
make -j10:      349s
make -j10/100:  253s
make -j100/100: 278s

It is remarkable, that 0.7 does not provide much advantage over compiling locally (6% speedup)
in a WLAN, while providing the expected 36% speedup for LAN. This proves that no-latency
provides significant wins for unstable/bad network connections and does not regress
performance for good networking setups. The overall 20% improvement is not bad at all.

2006-06-16 make-it-cool-branch:

make -j10/100:  244s
make -j1:       376s

result: correcting process accounting for local jobs makes -j1 fast again (just 2% overhead)

icecream, always compile remote even though host is not faster:

make -j10:       538s
make -j10/sched: 389s

As we can see, the scheduler improves performance by 38%.
